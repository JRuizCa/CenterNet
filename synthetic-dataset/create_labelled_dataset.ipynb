{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import requests\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "\n",
    "coco = COCO('./data/coco/annotations/instances_train2017.json')\n",
    "imgIds = coco.getImgIds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_dict = {\n",
    "    0: {'folder': \"barcodes\", 'longest_min': 150, 'longest_max': 400}\n",
    "}\n",
    "\n",
    "PATH_MAIN = \"data\"\n",
    "folder_name = obj_dict[0]['folder']\n",
    "\n",
    "files_imgs = sorted(os.listdir(os.path.join(PATH_MAIN, folder_name, 'images')))\n",
    "files_imgs = [os.path.join(PATH_MAIN, folder_name, 'images', f) for f in files_imgs]\n",
    "\n",
    "files_masks = sorted(os.listdir(os.path.join(PATH_MAIN, folder_name, 'masks')))\n",
    "files_masks = [os.path.join(PATH_MAIN, folder_name, 'masks', f) for f in files_masks]\n",
    "\n",
    "obj_dict[0]['images'] = files_imgs\n",
    "obj_dict[0]['masks'] = files_masks\n",
    "\n",
    "print(\"The first five files from the sorted list of barcode images:\", obj_dict[0]['images'][:5])\n",
    "print(\"\\nThe first five files from the sorted list of barcode masks:\", obj_dict[0]['masks'][:5])\n",
    "\n",
    "files_bg_imgs = os.listdir(os.path.join(PATH_MAIN, 'bg_2'))\n",
    "files_bg_imgs = [os.path.join(PATH_MAIN, 'bg_2', f) for f in files_bg_imgs]\n",
    "\n",
    "print(\"\\nThe first five files from the sorted list of background images:\", files_bg_imgs[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_and_mask(img_path, mask_path):\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    mask = cv2.imread(mask_path)\n",
    "    # mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    mask_b = ~mask[:,:,0] == 0 # This is boolean mask\n",
    "    mask = mask_b.astype(np.uint8) # This is binary mask\n",
    "    # mask = (mask - 1)*(-1) # invert mask\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(img, desired_max, desired_min=None):\n",
    "   \n",
    "    h, w = img.shape[0], img.shape[1]\n",
    "    \n",
    "    longest, shortest = max(h, w), min(h, w)\n",
    "    longest_new = desired_max\n",
    "    if desired_min:\n",
    "        shortest_new = desired_min\n",
    "    else:\n",
    "        shortest_new = int(shortest * (longest_new / longest))\n",
    "    \n",
    "    if h > w:\n",
    "        h_new, w_new = longest_new, shortest_new\n",
    "    else:\n",
    "        h_new, w_new = shortest_new, longest_new\n",
    "        \n",
    "    transform_resize = A.Compose([\n",
    "        A.Sequential([\n",
    "        A.Resize(h_new, w_new, interpolation=1, always_apply=False, p=1)\n",
    "        ], p=1)\n",
    "    ])\n",
    "\n",
    "    transformed = transform_resize(image=img)\n",
    "    img_r = transformed[\"image\"]\n",
    "        \n",
    "    return img_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_transform_obj(img, mask, longest_min, longest_max, transforms=False):\n",
    "   \n",
    "    h, w = mask.shape[0], mask.shape[1]\n",
    "    \n",
    "    longest, shortest = max(h, w), min(h, w)\n",
    "    longest_new = np.random.randint(longest_min, longest_max)\n",
    "    shortest_new = int(shortest * (longest_new / longest))\n",
    "    \n",
    "    if h > w:\n",
    "        h_new, w_new = longest_new, shortest_new\n",
    "    else:\n",
    "        h_new, w_new = shortest_new, longest_new\n",
    "        \n",
    "    transform_resize = A.Resize(h_new, w_new, interpolation=1, always_apply=False, p=1)\n",
    "\n",
    "    transformed_resized = transform_resize(image=img, mask=mask)\n",
    "    img_t = transformed_resized[\"image\"]\n",
    "    mask_t = transformed_resized[\"mask\"]\n",
    "        \n",
    "    if transforms:\n",
    "        transformed = transforms(image=img_t, mask=mask_t)\n",
    "        img_t = transformed[\"image\"]\n",
    "        mask_t = transformed[\"mask\"]\n",
    "        \n",
    "    return img_t, mask_t\n",
    "\n",
    "transforms_obj = A.Compose([\n",
    "    A.RandomRotate90(p=1),\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.2),\n",
    "                               contrast_limit=0.1,\n",
    "                               brightness_by_max=True,\n",
    "                               always_apply=False,\n",
    "                               p=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_obj(img_comp, mask_comp, img, mask, x, y, idx):\n",
    "    '''\n",
    "    img_comp - composition of objects\n",
    "    mask_comp - composition of objects` masks\n",
    "    img - image of object\n",
    "    mask - binary mask of object\n",
    "    x, y - coordinates where center of img is placed\n",
    "    Function returns img_comp in CV2 RGB format + mask_comp\n",
    "    '''\n",
    "    h_comp, w_comp = img_comp.shape[0], img_comp.shape[1]\n",
    "    \n",
    "    h, w = img.shape[0], img.shape[1]\n",
    "    \n",
    "    x = x - int(w/2)\n",
    "    y = y - int(h/2)\n",
    "    \n",
    "    mask_b = mask == 1\n",
    "    mask_rgb_b = np.stack([mask_b, mask_b, mask_b], axis=2)\n",
    "    \n",
    "    if x >= 0 and y >= 0:\n",
    "    \n",
    "        h_part = h - max(0, y+h-h_comp) # h_part - part of the image which gets into the frame of img_comp along y-axis\n",
    "        w_part = w - max(0, x+w-w_comp) # w_part - part of the image which gets into the frame of img_comp along x-axis\n",
    "\n",
    "        img_comp[y:y+h_part, x:x+w_part, :] = img_comp[y:y+h_part, x:x+w_part, :] * ~mask_rgb_b[0:h_part, 0:w_part, :] + (img * mask_rgb_b)[0:h_part, 0:w_part, :]\n",
    "        mask_comp[y:y+h_part, x:x+w_part] = mask_comp[y:y+h_part, x:x+w_part] * ~mask_b[0:h_part, 0:w_part] + (idx * mask_b)[0:h_part, 0:w_part]\n",
    "        mask_added = mask[0:h_part, 0:w_part]\n",
    "        \n",
    "    elif x < 0 and y < 0:\n",
    "        \n",
    "        h_part = h + y\n",
    "        w_part = w + x\n",
    "        \n",
    "        img_comp[0:0+h_part, 0:0+w_part, :] = img_comp[0:0+h_part, 0:0+w_part, :] * ~mask_rgb_b[h-h_part:h, w-w_part:w, :] + (img * mask_rgb_b)[h-h_part:h, w-w_part:w, :]\n",
    "        mask_comp[0:0+h_part, 0:0+w_part] = mask_comp[0:0+h_part, 0:0+w_part] * ~mask_b[h-h_part:h, w-w_part:w] + (idx * mask_b)[h-h_part:h, w-w_part:w]\n",
    "        mask_added = mask[h-h_part:h, w-w_part:w]\n",
    "        \n",
    "    elif x < 0 and y >= 0:\n",
    "        \n",
    "        h_part = h - max(0, y+h-h_comp)\n",
    "        w_part = w + x\n",
    "        \n",
    "        img_comp[y:y+h_part, 0:0+w_part, :] = img_comp[y:y+h_part, 0:0+w_part, :] * ~mask_rgb_b[0:h_part, w-w_part:w, :] + (img * mask_rgb_b)[0:h_part, w-w_part:w, :]\n",
    "        mask_comp[y:y+h_part, 0:0+w_part] = mask_comp[y:y+h_part, 0:0+w_part] * ~mask_b[0:h_part, w-w_part:w] + (idx * mask_b)[0:h_part, w-w_part:w]\n",
    "        mask_added = mask[0:h_part, w-w_part:w]\n",
    "        \n",
    "    elif x >= 0 and y < 0:\n",
    "        \n",
    "        h_part = h + y\n",
    "        w_part = w - max(0, x+w-w_comp)\n",
    "        \n",
    "        img_comp[0:0+h_part, x:x+w_part, :] = img_comp[0:0+h_part, x:x+w_part, :] * ~mask_rgb_b[h-h_part:h, 0:w_part, :] + (img * mask_rgb_b)[h-h_part:h, 0:w_part, :]\n",
    "        mask_comp[0:0+h_part, x:x+w_part] = mask_comp[0:0+h_part, x:x+w_part] * ~mask_b[h-h_part:h, 0:w_part] + (idx * mask_b)[h-h_part:h, 0:w_part]\n",
    "        mask_added = mask[h-h_part:h, 0:w_part]\n",
    "    \n",
    "    return img_comp, mask_comp, mask_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bg_with_noise(files_bg_imgs,\n",
    "                         bg_max=600,\n",
    "                         bg_min=600,\n",
    "                         blank_bg=False):\n",
    "    \n",
    "    if blank_bg:\n",
    "        img_comp_bg = np.ones((bg_min, bg_max,3), dtype=np.uint8) * 255\n",
    "        mask_comp_bg = np.zeros((bg_min, bg_max), dtype=np.uint8)\n",
    "    else:    \n",
    "        # idx = np.random.randint(len(files_bg_imgs))\n",
    "        # img_bg = cv2.imread(files_bg_imgs[idx])\n",
    "\n",
    "        img = coco.loadImgs(imgIds[np.random.randint(0,len(imgIds))])[0]\n",
    "        img_bg = io.imread(img['coco_url'])\n",
    "\n",
    "        img_comp_bg = resize_img(img_bg, bg_max, bg_min)\n",
    "\n",
    "    return img_comp_bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_areas(mask_comp, obj_areas, overlap_degree=0.3):\n",
    "    obj_ids = np.unique(mask_comp).astype(np.uint8)[1:-1]\n",
    "    masks = mask_comp == obj_ids[:, None, None]\n",
    "    \n",
    "    ok = True\n",
    "    \n",
    "    if len(np.unique(mask_comp)) != np.max(mask_comp) + 1:\n",
    "        ok = False\n",
    "        return ok\n",
    "    \n",
    "    for idx, mask in enumerate(masks):\n",
    "        if np.count_nonzero(mask) / obj_areas[idx] < 1 - overlap_degree:\n",
    "            ok = False\n",
    "            break\n",
    "            \n",
    "    return ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_composition(img_comp_bg,\n",
    "                       max_objs=3,\n",
    "                       overlap_degree=0,\n",
    "                       max_attempts_per_obj=10):\n",
    "\n",
    "    img_comp = img_comp_bg.copy()\n",
    "    h, w = img_comp.shape[0], img_comp.shape[1]\n",
    "    mask_comp = np.zeros((h,w), dtype=np.uint8)\n",
    "    \n",
    "    obj_areas = []\n",
    "    labels_comp = []\n",
    "    num_objs = np.random.randint(max_objs) + 2\n",
    "    i = 1\n",
    "    \n",
    "    for _ in range(1, num_objs):\n",
    "\n",
    "        obj_idx = 1 # 0 + 1  \n",
    "        \n",
    "        for _ in range(max_attempts_per_obj):\n",
    "            print(_)\n",
    "            print(max_attempts_per_obj)\n",
    "            imgs_number = len(obj_dict[0]['images'])\n",
    "            idx = np.random.randint(imgs_number)\n",
    "            img_path = obj_dict[0]['images'][idx]\n",
    "            mask_path = obj_dict[0]['masks'][idx]\n",
    "            img, mask = get_img_and_mask(img_path, mask_path)\n",
    "\n",
    "            x, y = np.random.randint(w), np.random.randint(h)\n",
    "            longest_min = obj_dict[0]['longest_min']\n",
    "            longest_max = obj_dict[0]['longest_max']\n",
    "            img, mask = resize_transform_obj(img,\n",
    "                                             mask,\n",
    "                                             longest_min,\n",
    "                                             longest_max,\n",
    "                                             transforms=transforms_obj)\n",
    "            if len(img)<3:\n",
    "                print(len(img))\n",
    "            if i == 1: # first objects\n",
    "                img_comp, mask_comp, mask_added = add_obj(img_comp,\n",
    "                                                          mask_comp,\n",
    "                                                          img,\n",
    "                                                          mask,\n",
    "                                                          x,\n",
    "                                                          y,\n",
    "                                                          i)\n",
    "                obj_areas.append(np.count_nonzero(mask_added))\n",
    "                labels_comp.append(obj_idx)\n",
    "                i += 1\n",
    "                break\n",
    "            else:        \n",
    "                img_comp_prev, mask_comp_prev = img_comp.copy(), mask_comp.copy()\n",
    "                img_comp, mask_comp, mask_added = add_obj(img_comp,\n",
    "                                                          mask_comp,\n",
    "                                                          img,\n",
    "                                                          mask,\n",
    "                                                          x,\n",
    "                                                          y,\n",
    "                                                          i)\n",
    "                ok = check_areas(mask_comp, obj_areas, overlap_degree)\n",
    "                if ok:\n",
    "                    obj_areas.append(np.count_nonzero(mask_added))\n",
    "                    labels_comp.append(obj_idx)\n",
    "                    i += 1\n",
    "                    break\n",
    "                else:\n",
    "                    print('OHHHHHH')\n",
    "                    img_comp, mask_comp = img_comp_prev.copy(), mask_comp_prev.copy()        \n",
    "        \n",
    "    return img_comp, mask_comp, labels_comp, obj_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yolo_annotations(mask_comp, labels_comp):\n",
    "    comp_w, comp_h = mask_comp.shape[1], mask_comp.shape[0]\n",
    "    \n",
    "    obj_ids = np.unique(mask_comp).astype(np.uint8)[1:]\n",
    "    # obj_ids = np.array([1], dtype=np.uint8)\n",
    "    masks = mask_comp == obj_ids[:, None, None]\n",
    "    annotations_yolo = []\n",
    "    for i in range(len(labels_comp)):\n",
    "        pos = np.where(masks[i])\n",
    "        xmin = np.min(pos[1])\n",
    "        xmax = np.max(pos[1])\n",
    "        ymin = np.min(pos[0])\n",
    "        ymax = np.max(pos[0])\n",
    "\n",
    "        xc = (xmin + xmax) / 2\n",
    "        yc = (ymin + ymax) / 2\n",
    "        w = xmax - xmin\n",
    "        h = ymax - ymin\n",
    "\n",
    "        annotations_yolo.append([labels_comp[i] - 1,\n",
    "                                round(xc/comp_w, 5),\n",
    "                                round(yc/comp_h, 5),\n",
    "                                round(w/comp_w, 5),\n",
    "                                round(h/comp_h, 5)])\n",
    "\n",
    "    return annotations_yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(imgs_number, folder, split='train'):\n",
    "    time_start = time.time()\n",
    "    for j in tqdm(range(imgs_number)):\n",
    "        img_comp_bg = create_bg_with_noise(files_bg_imgs)\n",
    "        \n",
    "        img_comp, mask_comp, labels_comp, _ = create_composition(img_comp_bg,\n",
    "                                                                 max_objs=3,\n",
    "                                                                 overlap_degree=0,\n",
    "                                                                 max_attempts_per_obj=2000)                                                      \n",
    "        img_comp = cv2.cvtColor(img_comp, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(os.path.join(folder, split, 'images/{}.jpg').format(j), img_comp)\n",
    "        annotations_yolo = create_yolo_annotations(mask_comp, labels_comp)\n",
    "        for i in range(len(annotations_yolo)):\n",
    "            with open(os.path.join(folder, split, 'labels/{}.txt').format(j), \"a\") as f:\n",
    "                f.write(' '.join(str(el) for el in annotations_yolo[i]) + '\\n')\n",
    "                \n",
    "    time_end = time.time()\n",
    "    time_total = round(time_end - time_start)\n",
    "    time_per_img = round((time_end - time_start) / imgs_number, 1)\n",
    "    \n",
    "    print(\"Generation of {} synthetic images is completed. It took {} seconds, or {} seconds per image\".format(imgs_number, time_total, time_per_img))\n",
    "    print(\"Images are stored in '{}'\".format(os.path.join(folder, split, 'images')))\n",
    "    print(\"Annotations are stored in '{}'\".format(os.path.join(folder, split, 'labels')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_dataset(1000, folder='dataset', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CenterNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3081503d0d9f25507061dcda75b75281b17d2469b56704e8a9b929dd15ec46ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
